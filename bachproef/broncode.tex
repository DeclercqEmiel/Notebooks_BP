\chapter{Broncode}
\label{ch:Broncode}
Hier staat alle code afgebeeld die gebruikt is voor het opstellen van deze bachelorproef.
De broncode kan ook teruggevonden worden op dit adres: \url{https://github.com/DeclercqEmiel/Notebooks_BP}

\section{Broncode datavoorbereiding}  % The \section*{} command stops section numbering

\captionof{listing}{Broncode datavoorbereiding}
\begin{minted}[
frame=lines,
framesep=2mm,
fontsize=\footnotesize,
linenos,breaklines
]{python}
#!/usr/bin/env python
# coding: utf-8

# In[2]:


import pandas as pd
import matplotlib.pylab as plt
import numpy as np


# # Dataset exploration

# ## Dataset #1: seaice

# source: https://www.kaggle.com/nsidcorg/daily-sea-ice-extent-data

# In[3]:


ice = pd.read_csv('./data/seaice.csv')
ice.columns = ['Year', 'Month', 'Day', 'Extent', 'Missing', 'Source Data',
'hemisphere']
ice


# In[5]:


plt.plot(ice[['Extent']])


# In[6]:


ice.groupby('hemisphere').count()


# In[7]:


ice.groupby('Year').count()[['Extent']]


# In[8]:


ice.groupby('Year').mean()[['Extent']]


# In[9]:


plt.scatter(ice.groupby('Year').mean()[['Extent']][:-1].index, ice.groupby('Year').mean()[['Extent']][:-1])


# In[10]:


ice.groupby(['Year','hemisphere']).count().tail(60)


# In[11]:


plt.xlabel('Years')
plt.ylabel('Extent')
plt.plot(ice[ice['hemisphere'] == 'north'].groupby('Year').mean()[['Extent']][:-1].index, ice[ice['hemisphere'] == 'north'].groupby('Year').mean()[['Extent']][:-1],label='Northern hemisphere')
plt.plot(ice[ice['hemisphere'] == 'south'].groupby('Year').mean()[['Extent']][:-1].index, ice[ice['hemisphere'] == 'south'].groupby('Year').mean()[['Extent']][:-1],label='Southern hemisphere')
plt.legend()


# In[12]:


plt.xlabel('Years')
plt.ylabel('Extent')
plt.scatter(ice.groupby('Year').mean()[['Extent']][:-1].index, ice.groupby('Year').mean()[['Extent']][:-1])


# In[ ]:





# In[13]:


print('start : ' + str(ice['Year'][0]))
print('end : ' + str(ice['Year'].tail(1).iloc[0]))


# In[14]:


2019-1978


# ## Dataset #1: Toronto_temp

# In[8]:


tt


# In[4]:


# Source: https://www.kaggle.com/rainbowgirl/climate-data-toronto-19372018
tt = pd.read_csv('./data/Toronto_temp.csv')
tt = tt[tt['Day'] == 1]
tt['Year'] = tt['Year'].replace({'2,013':'2013',
'2,014':'2014',
'2,015':'2015',
'2,016':'2016',
'2,017':'2017',
'2,018':'2018'})
# tt.groupby('Year').count()
tt = tt[(tt['Year'] != '1937')]
ttt = tt.groupby('Year').count()
#ttt.head(50)
#tt.groupby('Year').count().tail(50)
meantt = tt.groupby('Year').mean()['Mean Temp (C)']
meantt
#meantt.index
#meantt
meantt.sort_index(inplace=True)

plt.xlabel('Years')
plt.ylabel('Temperature (C)')
plt.xticks(np.array(range(0,meantt.size,10)))
plt.scatter(meantt.index, meantt)

print('start : ' + meantt.index[0])
print('end : ' + meantt.index[-1])

new_row = pd.Series({'Mean Temp (C)' : 0.555556, 'Year': '2018', 'Month':12})
tt = tt.append(new_row, ignore_index=True)
tt['Year'] = tt['Year'].astype(int)
mean_temp_monthly = tt[['Year','Month','Mean Temp (C)']].set_index(['Year','Month']).sort_index()
# mean_temp_monthly
mean_temp_monthly = mean_temp_monthly[mean_temp_monthly.index.get_level_values(0).astype(int) >= 1979 ]
mean_temp_monthly


# In[6]:


tt


# ## Dataset #3: seaice2

# Completer version of dataset #1
# 
# source: https://nsidc.org/arcticseaicenews/sea-ice-tools/

# In[13]:


ice2.mean()[1:-2]


# In[17]:


ice2_mean


# In[19]:


ice2.mean()[1:-2]


# In[24]:


ice2.mean()


# In[26]:


ice2


# In[27]:


ice2 = pd.read_csv('./data/seaice2.csv')
# ice2
ice2_mean = ice2.mean()[1:-2]
ice2_mean
ice2_mean.index = ice2_mean.index.values.astype(int)

plt.title('Yearly ice extent')
plt.scatter(ice2_mean.index,ice2_mean)
plt.xlabel('Years')
plt.ylabel('Extent')
plt.show()

# ice2['2018']
# pd.concat([ice2['2016'],ice2['2017'],ice2['2018'],ice2['2019']]).reset_index()[0]
# ice2[['2018']].append(ice2[['2019']])
ice2.rename(columns={'Unnamed: 0' : 'Month', 'Unnamed: 1' : 'Day'}, inplace = True)
ice2.drop([' ','1981-2010','Day','1978','2020'],axis=1,inplace=True)
values = ice2.values
i = 0
for row in values :
if type(row[0]) != str :
values[i][0] = month
else:
month = row[0]
i = i +1
# ice2.columns.values
ice2_clean = pd.DataFrame(values)
ice2_clean.columns = ice2.columns.values
# ice2_clean.head(5)
ice2_monthly_mean = ice2_clean.set_index('Month').astype(float).groupby('Month',sort=False).mean()
# ice2_monthly_mean
# ice2_monthly_mean.T.stack().index.get_level_values(0)
# ice2_monthly_mean.T.stack().reset_index(level=['Month']).drop(columns=['Month'])
ice2_monthly_mean_chron = ice2_monthly_mean.T.stack().reset_index(level=['Month']).drop(columns=['Month'])
# ice2.columns.size
plt.title('Monthly ice extent')
plt.plot(ice2_monthly_mean_chron.values)
plt.xticks(np.array(range(0,500,75)))
plt.xlabel('Cumulative month')
plt.ylabel('Extent')
plt.show()

# np.unique(ice2_monthly_mean_chron.index.values).size*12
print('from ' + ice2_monthly_mean_chron.index.values[0] + ' until ' + ice2_monthly_mean_chron.index.values[-1])
ice2_monthly_mean_chron = ice2_monthly_mean.T.stack().reset_index(level=['Month']).drop(columns=['Month'])
ice2_monthly_mean_chron.columns = ['ice_extent']
ice2_monthly_mean_chron


# # Dataset Combination

# In[54]:


ice2_monthly_mean_chron_cut = ice2_monthly_mean_chron[:-12]
# ice2_monthly_mean_chron
# ice2_monthly_mean_chron_cut
# mean_temp_monthly
# ice2_monthly_mean_chron_cut
combined = mean_temp_monthly[mean_temp_monthly.index.get_level_values(0) >= 1979]
combined['ice_extent'] = ice2_monthly_mean_chron_cut.values
# combined
combined.rename(columns={'Mean Temp (C)': 'mean_temp'}, inplace=True)
dataframe_monthly = combined
# dataframe_monthly
# dataframe_monthly[['mean_temp']]
plt.plot(dataframe_monthly[['mean_temp']].values[-24:],label='temperature')
plt.plot(dataframe_monthly[['ice_extent']].values[-24:],label='ice extent')
plt.legend()
plt.show()
dataframe_yearly = combined.groupby('Year').mean()
# dataframe_yearly
# dataframe_monthly[['mean_temp']].values
plt.plot(dataframe_monthly[['mean_temp']].values,label='temperature')
plt.plot(dataframe_monthly[['ice_extent']].values,label='ice extent')
plt.legend()
dataframe_monthly.to_csv('./data/dataframe_monthly.csv')
dataframe_yearly.to_csv('./data/dataframe_yearly.csv')
\end{minted}

\clearpage
\section{Broncode voor het vergelijken van ARIMA, LSTM en Prophet bij univariate, niet-seizoensgebonden tijdreeksen}  % The \section*{} command stops  numbering
\captionof{listing}{code voor differentiatie}
\begin{minted}[
frame=lines,
framesep=2mm,
fontsize=\footnotesize,
linenos,breaklines
]{python}

#!/usr/bin/env python
# coding: utf-8

# # Imports 

# In[1]:


import pandas as pd
import numpy as np
import matplotlib.pylab as plt
get_ipython().run_line_magic('matplotlib', 'inline')
from matplotlib.pylab import rcParams
rcParams['figure.figsize'] = 15,5
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error
import warnings
from statsmodels.tsa.arima_model import ARIMA
import timeit
from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
import tensorflow as tf
from fbprophet import Prophet


# # Dataprep

# In[2]:


# read time series
ts = pd.read_csv('./data/dataframe_yearly.csv', index_col=0, usecols=[0,2])

# print out first values
ts.head()


# In[3]:


# plot time series
plt.plot(ts)


# ## Differentiatie

# In[4]:


# define method to visualise the stationarity of a time series
def test_stationarity(timeseries):
    
    #Determing rolling statistics
    rolmean = timeseries.rolling(12).mean()
    rolstd = timeseries.rolling(12).std()

    #Plot rolling statistics:
    orig = plt.plot(timeseries, color='blue',label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
    std = plt.plot(rolstd, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation')
    plt.show(block=False)
    
# check stationarity of time serie
test_stationarity(ts)


# In[5]:


# take the random walk difference of the time serie
ts_diff = ts - ts.shift(1)
ts_diff = ts_diff.dropna()

# display stationarity of the newly differenced time serie
test_stationarity(ts_diff)


# ## Cross validation setup

# In[6]:


# initialize TimeSeriesSplit object
tscv = TimeSeriesSplit(n_splits = 8)

# loop trough all split time series that have a trainingsset with more than 20 values
for train_index, test_index in tscv.split(ts_diff):
    if train_index.size > 20:

        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]
        
         # visiualize cross_validation structure for reference
        print("TRAIN:", train_index.size)
        print("TEST:", test_index.size)
        print()


# ## General methods

# In[7]:


# plot
plt.plot(ts, marker='o', color='blue',label='Actual values')
plt.ylim([0,15])
plt.legend()

plt.show()


# In[8]:


# define functions used troughout the notebook

# define function for plotting last prediction and the actual data
def full_graph(predicted_diff, title):
    
    # format predictions by adding NaN values in front
    predictionsArray = np.asarray(revert_diff(predicted_diff, ts))
    zerosArray = np.zeros(ts.values.size-len(predictionsArray.flatten()))
    cleanPrediction = pd.Series(np.concatenate((zerosArray,predictionsArray))).replace(0,np.NaN)
    cleanPrediction.index = ts.index.values
    
    # plot
    plt.title(title)
    plt.plot(ts, marker='o', color='blue',label='Actual values')
    plt.plot(cleanPrediction, marker='o', color='red',label='Last 4 year prediction')
    plt.ylim([0,15])
    plt.legend()

    plt.show()

# define function for reverting a differenced dataset
def revert_diff(predicted_diff, og_data):
    
    # retrieve last value
    last_value = og_data.iloc[-predicted_diff.size-1][0]
    
    # initialize reverted array
    predicted_actual = np.array([])
    
    # add each value in the differenced array with the last actual value
    for value_diff in predicted_diff:
        actual_value = last_value + value_diff
        predicted_actual = np.append(predicted_actual, actual_value)
        last_value = actual_value
        
    return predicted_actual


# # ARIMA

# In[9]:


# ARIMA
from statsmodels.tsa.arima_model import ARIMA
import itertools
import warnings
import sys
from sklearn.metrics import mean_absolute_error



# Define the p, d and q parameters to take any value between 0 and 2
p = q = range(0, 5)
d = range(0,3)

# Generate all different combinations of p, q and q triplets
pdq = list(itertools.product(p, d, q))

# initialize variables
best_pdq = pdq
best_mean_mae = np.inf

# specify to ignore warning messages to reduce visual clutter
warnings.filterwarnings("ignore") 

# loop trough all possible parameter combinations of pdq
for param in pdq:
    print(param)
    
    # some parametercombinations might lead to crash, so catch exceptions and continue
    try:  
        
        # initialize the array which will contain the mean average errors
        maes = []
        
        # loop trough all split time series that have a trainingsset with more than 20 values
        for train_index, test_index in tscv.split(ts_diff):
            if train_index.size > 20:
                
                # initialize cross validation train and test sets
                cv_train, cv_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

                # build model
                model = ARIMA(cv_train, order=(param))
                
                # fit model
                model_fit = model.fit()

                # make predictions
                predictions =  model_fit.predict(start=len(cv_train), end=len(cv_train)+cv_test.size-1, dynamic=False)
                
                # renaming for clarity
                prediction_values = predictions.values
                true_values = cv_test.values
                
                # error calculation this part of the cross validation
                maes.append(mean_absolute_error(true_values, prediction_values))

        
        # error calculation for this parameter combination
        mean_mae = np.mean(maes)
        print('MAE: ' + str(mean_mae))    

        # store parameters resulting in the lowest mean MAE
        if mean_mae < best_mean_mae:
            best_mean_mae = mean_mae
            best_maes = maes
            best_pdq = param
            best_predictions = prediction_values
            
    except Exception as e:
        print(e)
        continue

# logging
print()
print('Best MAE = ' + str(best_mean_mae))
print(best_pdq)

# best range(0,10): 


# In[10]:


# # result
# best_pdq = (3, 0, 0)


# In[11]:


start_time = timeit.default_timer()

# specify to ignore warning messages
warnings.filterwarnings("ignore") 

print("----")

# initialize the array which will contain the mean average errors
maes = []

# loop trough all split time series that have a trainingsset with more than 20 values
for train_index, test_index in tscv.split(ts_diff):
    if train_index.size > 20:

        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

        # build model
        arima = ARIMA(cv_train, best_pdq).fit(start_ar_lags=1,disp=False)

        # make predictions
        predictions = arima.forecast(steps=4)
        prediction_values = predictions[0]
        true_values = cv_test.values

        # error calc
        maes.append(mean_absolute_error(true_values, prediction_values))

        # last actual prediction 
        last_prediction_ARIMA = prediction_values

        print("I",end="")

# store results to variables
time_ARIMA = timeit.default_timer() - start_time
mae_mean = np.mean(maes)
MAE_ARIMA = mae_mean
last_MAE_ARIMA = maes[-1]

# logging
print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_ARIMA)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_ARIMA)
print('Execution time: %.3f seconds' % time_ARIMA)
full_graph(last_prediction_ARIMA, 'Last prediction ARIMA')
print('Mean average errors:')
print(maes)


# # LSTM

# https://machinelearningmastery.com/tune-lstm-hyperparameters-keras-time-series-forecasting/

# ## Functions 

# In[12]:


from keras.layers import Dropout
# split a univariate sequence into samples
def split_sequence(sequence, n_steps_in, n_steps_out):
    X, y = list(), list()
    for i in range(len(sequence)):
        # find the end of this pattern
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        
        # check if we are beyond the sequence
        if out_end_ix > len(sequence):
            break
            
        # gather input and output parts of the pattern
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return array(X), array(y)
 
def build_model(raw_seq, n_steps_in, n_steps_out, n_features, n_neurons, dropout, batch_s):
    
    # split into samples
    X, y = split_sequence(raw_seq.values.flatten(), n_steps_in, n_steps_out)
    
    # reshape from [samples, timesteps] into [samples, timesteps, features]
    X = X.reshape((X.shape[0], X.shape[1], n_features))
    
    # define model
    model = Sequential()
    model.add(LSTM(n_neurons, activation='relu'))
    model.add(Dropout(dropout))
    model.add(Dense(n_steps_out))
    model.compile(optimizer='adam', loss='mae')
    
    # fit model
    model.fit(X, y, batch_size=batch_s, epochs=100, verbose=0)
    
    return model


def predict(x_input, model, n_features):
    n_features = 1
    
    # reshape data
    x_input = x_input.reshape((1, n_steps_in, n_features))
    
    # predict
    yhat = model.predict(x_input, verbose=0)
    
    return yhat


# ## Determine hyperparameters 

# In[24]:


# Disabled tf warning because of visual clutter
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


# constant variables
n_steps_in = 4
n_steps_out = 4
n_features  = 1
maes = []
global_maes = []

# optimizable variables
n_neurons_array = [1,10,20]
dropout_array = [0,0.5,0.99]
batch_size_array = [1,8]


# initialize values
best_MAE = 100
best_n_neurons = 0
best_activation = 'none'
best_dropout = 0
best_batch_size = 0

# loop over all possible parameter combinations
for n_neurons in n_neurons_array:
    for dropout in dropout_array:
        for batch_size in batch_size_array:

            print("----")
            
            # loop trough all split time series that have a trainingsset with more than 20 values
            for train_index, test_index in tscv.split(ts_diff): 
                if train_index.size > 20:  
                    
                    # initialize cross validation train and test sets
                    y_train, y_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

                    # build model
                    lstm_model = build_model(y_train, n_steps_in, n_steps_out, n_features, n_neurons, dropout, batch_size)

                    # make predictions
                    x_input = array(y_test)
                    y_predicted = predict(x_input, lstm_model, n_features).flatten()
                    y_actual = y_test.values

                    # error calculation this part of the cross validation
                    maes.append(mean_absolute_error(y_actual, y_predicted))

                    print("I",end="")

                    # last actual prediction 
                    last_prediction_LSTM = y_predicted

            # error calculation for this parameter combination
            MAE_LSTM = np.mean(maes)
            last_MAE_LSTM = maes[-1]
            global_maes.append(MAE_LSTM)

            # store parameters resulting in the lowest mean MAE
            if best_MAE > MAE_LSTM:
                best_n_neurons = n_neurons
                best_dropout = dropout
                best_batch_size = batch_size
                best_MAE = MAE_LSTM
                
            # log values for parameter combination
            print()
            print(n_neurons)
            print(dropout)
            print(batch_size)
            print(MAE_LSTM)
            print()    

# log parameter combination with best result
print('Best:')
print('N neurons')
print(best_n_neurons)
print('Dropout rate')
print(best_dropout)
print('Batch size')
print(best_batch_size)
print('MAE')
print(best_MAE)
plt.bar(range(0,len(global_maes)), global_maes)


# In[25]:


# Run #1 Best:
# 1
# 0
# 1
# 0.1919512481592649
# Wall time: 8min 36s

# Run #2 Best:
# 1
# 0.5
# 1
# 0.19969739902546374
# Wall time: 7min 16s

# Run #3 Best:
# 5
# 0.99
# 8
# 0.20111841616444215
# Wall time: 6min 47s


# In[26]:


best_n_neurons = 1
best_dropout = 0
best_batch_s = 8


# ## Final result LSTM

# In[27]:


start_time = timeit.default_timer()

# Disabled tf warning because of visual clutter
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


# constant variables
n_steps_in = 4
n_steps_out = 4
n_features  = 1
maes = []


# optimizable variables
n_neurons = best_n_neurons
dropout = best_dropout
batch_s = best_batch_s

print("----")

# loop trough all split time series that have a trainingsset with more than 20 values
for train_index, test_index in tscv.split(ts_diff):
    if train_index.size > 20:  
        # initialize cross validation train and test sets
        y_train, y_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

        # build model
        lstm_model = build_model(y_train, n_steps_in, n_steps_out, n_features, n_neurons, dropout, batch_s)

        # make predictions
        x_input = array(y_test)
        y_predicted = predict(x_input, lstm_model, n_features).flatten()
        y_actual = y_test.values

        # error calc
        maes.append(mean_absolute_error(y_actual, y_predicted))

        print("I",end="")

# last actual prediction 
last_prediction_LSTM = y_predicted
 
# store variables
time_LSTM = timeit.default_timer() - start_time
MAE_LSTM = np.mean(maes)
last_MAE_LSTM = maes[-1]

# visualisation
print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_LSTM)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_LSTM)
print('Execution time: %.3f seconds' % time_LSTM)
full_graph(last_prediction_LSTM, 'Last prediction LSTM')
print('Mean average errors')
print(maes)


# # Prophet

# In[28]:


# formatting dataframe
ts_formated_prophet = ts_diff.reset_index().rename(columns = {'Year' : 'ds', 'ice_extent' : 'y'})
ts_formated_prophet['ds'] = pd.DataFrame(pd.to_datetime(ts_formated_prophet['ds'].astype(str), format='%Y'))


# In[38]:


# Python
import itertools
import numpy as np
import pandas as pd

# define dataframe
df = ts_formated_prophet

param_grid = {  
    'changepoint_prior_scale': [0.001, 0.01, 0.1, 1, 2, 5, 10, 15, 20, 25],
}

# Generate all combinations of parameters
all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]

# initialize variables
maes = []  
global_maes = []
best_MAE_prophet = np.inf

# Use cross validation to evaluate all parameters
for params in all_params:

    # loop trough all split time series that have a trainingsset with more than 20 values
    for train_index, test_index in tscv.split(ts_formated_prophet):    
        if train_index.size > 20:  
            
            # initialize cross validation train and test sets
            train  = ts_formated_prophet.iloc[train_index]
            y_test = ts_formated_prophet.iloc[test_index][['y']].values.flatten()
            X_test = ts_formated_prophet.iloc[test_index][['ds']]

            # Fit model with given params
            model = Prophet(**params, weekly_seasonality=False, daily_seasonality=False)
            model = model.fit(train)
            
            # make predictions
            forecast = model.predict(X_test)
            y_pred = forecast['yhat'].values
            
            # last actual prediction 
            last_prediction_prophet = y_pred
            
            # error calculation this part of the cross validation
            maes.append(mean_absolute_error(y_test, y_pred))
            
    # error calculation for this parameter combination
    MAE_prophet = np.mean(maes)
    last_MAE_prophet = maes[-1]
    global_maes.append(MAE_prophet)
    
    # logging
    print('changepoint_prior_scale: ' + str(params['changepoint_prior_scale']))
    
    # store parameters resulting in the lowest mean MAE
    if best_MAE_prophet > MAE_prophet:
        best_params = params
        best_MAE_prophet = MAE_prophet

# log optimal result          
print('changepoint_prior_scale: ' + str(best_params['changepoint_prior_scale']))
print(best_MAE_prophet)
            


# In[39]:


# best_params = {'changepoint_prior_scale': 2}


# In[40]:


# Disabled tf warning because of clutter
warnings.filterwarnings("ignore") # specify to ignore warning messages

start_time = timeit.default_timer()

# initialize variables
maes = []

for train_index, test_index in tscv.split(ts_formated_prophet):
    if train_index.size > 20:  
        
        # initialize cross validation train and test sets
        train  = ts_formated_prophet.iloc[train_index]
        y_test = ts_formated_prophet.iloc[test_index][['y']].values.flatten()
        X_test = ts_formated_prophet.iloc[test_index][['ds']]

        # build model
        model = Prophet(**best_params, weekly_seasonality=False, daily_seasonality=False)
        model.fit(train)

        # make predictions
        forecast = model.predict(X_test)
        y_pred = forecast['yhat'].values

        # error calc
        maes.append(mean_absolute_error(y_test, y_pred))

        # last actual prediction 
        last_prediction_prophet = y_pred


# store results
time_Prophet = timeit.default_timer() - start_time
MAE_Prophet = np.mean(maes)
last_MAE_Prophet = maes[-1]

# visualize results
print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_Prophet)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_Prophet)
print('Execution time: %.3f seconds' % time_Prophet)
full_graph(last_prediction_prophet, "Last 4 year prediction prophet")
print('Mean average errors')
print(maes)


# # Evaluation

# In[33]:


# formatting
results = [[MAE_ARIMA,time_ARIMA,last_MAE_ARIMA],[MAE_LSTM,time_LSTM,last_MAE_LSTM],[MAE_Prophet,time_Prophet,last_MAE_Prophet]]

# display results
pd.DataFrame(results, columns=['Mean MAE (x 1 000 000 km\u00b2)','Execution time (s)','Last MAE (x 1 000 000 km\u00b2)'],index=['ARIMA','LSTM','Prophet']).round(decimals=3)


# In[34]:


# visualize results of last prediction
full_graph(last_prediction_ARIMA, "Last prediction ARIMA")
full_graph(last_prediction_LSTM, "Last prediction LSTM")
full_graph(last_prediction_prophet, "Last prediction Prophet")



\end{minted}

\section{Broncode voor het vergelijken van ARIMA, LSTM en Prophet bij univariate, seizoensgebonden tijdreeksen}  % The \section*{} command stops section numbering
\captionof{listing}{Broncode voor het vergelijken van ARIMA, LSTM en Prophet bij univariate, seizoensgebonden tijdreeksen}
\begin{minted}[
frame=lines,
framesep=2mm,
fontsize=\footnotesize,
linenos,breaklines
]{python}

#!/usr/bin/env python
# coding: utf-8

# In[40]:


# Voorspellen voor 1 jaar
# Of voorspellen op 3 jaar apart omdat voorspellen van 1 jaar misschien de algemene trend minder volgt
# SARIMA proberen anders gwn ARIMA


# In[41]:


import pandas as pd
import numpy as np
# matplotlib is the Python library for drawing diagrams
import matplotlib.pylab as plt
get_ipython().run_line_magic('matplotlib', 'inline')
# set the size of the diagrams
from matplotlib.pylab import rcParams
rcParams['figure.figsize'] = 15,5
import timeit
import warnings
from sklearn.model_selection import TimeSeriesSplit


# # General functions

# In[42]:


def test_stationarity(timeseries):
    
    #Determing rolling statistics
    rolmean = timeseries.rolling(36).mean()
    rolstd = timeseries.rolling(24).std()

    #Plot rolling statistics:
    orig = plt.plot(timeseries, color='blue',label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
    std = plt.plot(rolstd, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation')
    plt.show(block=False)
    
def full_graph(predicted, og_dataset, title):
    zerosArray = np.zeros(og_dataset.values.size-len(predicted.flatten()))
    cleanPrediction = pd.Series(np.concatenate((zerosArray,predicted))).replace(0,np.NaN)
    
    # plot
    plt.title(title)
    plt.plot(og_dataset.index, og_dataset.values,marker='o', color='blue',label='Actual values')
    plt.plot(og_dataset.index, cleanPrediction,marker='o', color='red',label='Last 2 year prediction')
    plt.ylim([0,20])
    plt.legend()

    plt.show()
    
def revert_diff(predicted_diff, og_data):
    last_value = og_data.iloc[-predicted_diff.size-1][0]
    predicted_actual = np.array([])
    for value_diff in predicted_diff:
        actual_value = last_value + value_diff
        predicted_actual = np.append(predicted_actual, actual_value)
        last_value = actual_value
    return predicted_actual

def revert_seasonal_diff_recursion(last_seasons_value, diff_value):
    return last_seasons_value + diff_value

def revert_diff_seasonal(predicted_diff, og_data):
    prediction_size = predicted_diff.size
    
    history = ts[:-prediction_size].values.flatten()
    for value_diff in predicted_diff[-prediction_size:]:
        new_value = revert_seasonal_diff_recursion(history[-12], value_diff)
        history = np.append(history,new_value)
    return history[-prediction_size:]


# ## Dataprep

# In[43]:


ts = pd.read_csv('./data/dataframe_monthly.csv', index_col=0, usecols=[0,1,3]).reset_index()


# In[44]:


ts


# In[45]:


ts['date'] = pd.to_datetime(ts['Month'].astype(str) + ts['Year'].astype(str), format='%m%Y', errors='ignore')


# In[46]:


ts


# In[47]:


ts = ts[['date','ice_extent']]
ts.set_index('date', inplace=True)
plt.plot(ts[['ice_extent']])


# In[48]:


test_stationarity(ts)


# ### Differencing

# In[49]:


ts_diff_seasonal = ts - ts.shift(12)
ts_diff_seasonal = ts_diff_seasonal.dropna()
test_stationarity(ts_diff_seasonal)


# In[50]:


ts_diff = ts - ts.shift(1)
ts_diff = ts_diff.dropna()
test_stationarity(ts_diff)


# ### Cross validation setup

# In[51]:


def display_cross_validation(dataset, n_splits):
    tscv = TimeSeriesSplit(n_splits = n_splits)
    
    for train_index, test_index in tscv.split(dataset):
        if train_index.size > 300:
            # initialize cross validation train and test sets
            cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]

            print("TRAIN:", train_index.size) # visiualize cross_validation structure for reference
            print("TEST:", test_index.size)
            print()


# In[52]:


ts_diff = ts_diff[:-5] # need the -5 to get testsets for 24 months/2 years
display_cross_validation(ts_diff, 18)
tscv_diff = TimeSeriesSplit(n_splits = 18)


# In[53]:


display_cross_validation(ts_diff_seasonal, 18)
tscv_diff_seasonal = TimeSeriesSplit(n_splits = 18)


# # ARIMA

# ## random walk differencing

# ### Determine hyperparameters

# In[20]:


# ARIMA
from statsmodels.tsa.arima_model import ARIMA
import itertools
import warnings
import sys
from sklearn.metrics import mean_absolute_error



# Define the p, d and q parameters to take any value between 0 and 2
p = q = range(0, 5)
d = range(0,3)

# Generate all different combinations of p, q and q triplets
pdq = list(itertools.product(p, d, q))
best_pdq = pdq
best_mean_mae = np.inf
warnings.filterwarnings("ignore") # specify to ignore warning messages
for param in pdq:
    print(param)
    try:   # some parametercombinations might lead to crash, so catch exceptions and continue
        maes = []
        for train_index, test_index in tscv_diff.split(ts_diff):
            if train_index.size > 300:
                # initialize cross validation train and test sets
                cv_train, cv_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

                # build model
                model = ARIMA(cv_train, order=(param))
                model_fit = model.fit()

                # make predictions
                predictions =  model_fit.predict(start=len(cv_train), end=len(cv_train)+cv_test.size-1, dynamic=False)
                prediction_values = predictions.values
                true_values = cv_test.values
                # error calc
                #     print(true_values)
                #     print(predictions.values)
                maes.append(mean_absolute_error(true_values, prediction_values))

        
        mean_mae = np.mean(maes)
        print('MAE: ' + str(mean_mae))    

        if mean_mae < best_mean_mae:
            best_mean_mae = mean_mae
            best_maes = maes
            best_pdq = param
            best_predictions = prediction_values
    except Exception as e:
        print(e)
        continue
   
print()
print('Best MAE = ' + str(best_mean_mae))
print(best_pdq)


# best range(0,10)
# Best MAE = 0.23763938034311669
# (8, 0, 9)
# Wall time: 1h 32min 14s


# In[54]:


# best_pdq = (8, 0, 9) # range 10
best_pdq = (3,0,3)


# ### Final result

# In[55]:


from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_absolute_error


start_time = timeit.default_timer()

warnings.filterwarnings("ignore") # specify to ignore warning messages

print("-------")

maes = []

for train_index, test_index in tscv_diff.split(ts_diff):
    if train_index.size > 300:
        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

        # build model
        model = ARIMA(cv_train, order=(best_pdq))
        model_fit = model.fit()

        # make predictions
        predictions =  model_fit.predict(start=len(cv_train), end=len(cv_train)+cv_test.size-1, dynamic=False)
        prediction_values = predictions.values
        true_values = cv_test.values

        # error calc
    #     print(true_values)
    #     print(predictions.values)
        maes.append(mean_absolute_error(true_values, prediction_values))

        print("I",end="")

time_ARIMA = timeit.default_timer() - start_time
mae_mean = np.mean(maes)
MAE_ARIMA = mae_mean
last_MAE_ARIMA = maes[-1]
last_prediction_ARIMA = prediction_values

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_ARIMA)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_ARIMA)
print('Execution time: %.3f seconds' % time_ARIMA)

reverted_prediction_values = revert_diff(last_prediction_ARIMA, ts[:-5])
full_graph(reverted_prediction_values, ts[:-5],'Last 2 year prediction ARIMA with regular differencing')
print(maes)


# ## Seasonal differencing

# ### Determine hyperparameters

# In[22]:


# ARIMA
from statsmodels.tsa.arima_model import ARIMA
import itertools
import warnings
import sys
from sklearn.metrics import mean_absolute_error



# Define the p, d and q parameters to take any value between 0 and 2
p = q = range(0, 5)
d = range(0,3)

# Generate all different combinations of p, q and q triplets
pdq = list(itertools.product(p, d, q))
best_pdq = pdq
best_mean_mae = np.inf
warnings.filterwarnings("ignore") # specify to ignore warning messages
for param in pdq:
    print(param)
    try:   # some parametercombinations might lead to crash, so catch exceptions and continue
        maes = []
        for train_index, test_index in tscv_diff_seasonal.split(ts_diff_seasonal):
            if train_index.size > 300:
                # initialize cross validation train and test sets
                cv_train, cv_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

                # build model
                model = ARIMA(cv_train, order=(param))
                model_fit = model.fit()

                # make predictions
                predictions =  model_fit.predict(start=len(cv_train), end=len(cv_train)+cv_test.size-1, dynamic=False)
                prediction_values = predictions.values
                true_values = cv_test.values
                # error calc
                #     print(true_values)
                #     print(predictions.values)
                maes.append(mean_absolute_error(true_values, prediction_values))

        
        mean_mae = np.mean(maes)
        print('MAE: ' + str(mean_mae))    

        if mean_mae < best_mean_mae:
            best_mean_mae = mean_mae
            best_maes = maes
            best_pdq = param
            best_predictions = prediction_values
    except Exception as e:
        print(e)
        continue
   
print()
print('Best MAE = ' + str(best_mean_mae))
print(best_pdq)



# ### Final result

# In[56]:


best_pdq=(3,0,3) # pq range 4
# best_pdq=(8, 0, 6) # pq range 10


# In[57]:


from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_absolute_error


start_time = timeit.default_timer()

warnings.filterwarnings("ignore") # specify to ignore warning messages

print("------")

maes = []

for train_index, test_index in tscv_diff_seasonal.split(ts_diff_seasonal):
    if train_index.size > 300:
        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

        # build model
        model = ARIMA(cv_train, order=(best_pdq))
        model_fit = model.fit()

        # make predictions
        predictions =  model_fit.predict(start=len(cv_train), end=len(cv_train)+cv_test.size-1, dynamic=False)
        prediction_values = predictions.values
        true_values = cv_test.values

        # error calc
    #     print(true_values)
    #     print(predictions.values)
        maes.append(mean_absolute_error(true_values, prediction_values))

        print("I",end="")

time_ARIMA_seasonal = timeit.default_timer() - start_time
mae_mean = np.mean(maes)
MAE_ARIMA_seasonal = mae_mean
last_MAE_ARIMA_seasonal = maes[-1]
last_prediction_ARIMA_seasonal = prediction_values

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_ARIMA_seasonal)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_ARIMA_seasonal)
print('Execution time: %.3f seconds' % time_ARIMA_seasonal)

reverted_prediction_values = revert_diff_seasonal(last_prediction_ARIMA_seasonal, ts)
full_graph(reverted_prediction_values, ts,'Last 2 year prediction ARIMA with seasonal differencing')
print(maes)


# # SARIMAX

# ## Random walk differencing

# In[76]:


# SARIMAX

import itertools
import warnings
import sys
from statsmodels.tsa.statespace.sarimax import SARIMAX


# Define the p, d and q parameters to take any value between 0 and 2
p = q = P = D = Q = range(0, 3)
d = D = range(0, 2)

# Generate all different combinations of p, q and q triplets
pdqPDQ = list(itertools.product(p, d, q , P, D, Q))
best_pdqPDQ = pdqPDQ
best_mean_mae = np.inf
warnings.filterwarnings("ignore") # specify to ignore warning messages
for param in pdqPDQ:
    print(param)
    try:   # some parametercombinations might lead to crash, so catch exceptions and continue
        maes = []
        for train_index, test_index in tscv_diff.split(ts_diff):
            if train_index.size > 300:
                # initialize cross validation train and test sets
                cv_train, cv_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

                # build model
                model = SARIMAX(cv_train, 
                order=param[:3], 
                seasonal_order=(12,)+param[3:])
                model_fit = model.fit()

                # make predictions
#                 predictions =  model_fit.predict(start=len(cv_train), end=len(cv_train)+cv_test.size-1, dynamic=False)
                predictions =  model_fit.forecast(steps=24)
                prediction_values = predictions.values
                true_values = cv_test.values
                # error calc
                #     print(true_values)
                #     print(predictions.values)
                maes.append(mean_absolute_error(true_values, prediction_values))

        
        mean_mae = np.mean(maes)
        print('MAE: ' + str(mean_mae))    

        if mean_mae < best_mean_mae:
            best_mean_mae = mean_mae
            best_maes = maes
            best_pdqPDQ = param
            best_predictions = prediction_values
    except Exception as e:
        print(e)
        continue

print(best_predictions.size)
print(data_test.index.size)

        
predictions_df = pd.DataFrame(best_predictions).set_index(keys=data_test.index)

# plot
print()
print('Best MAE = ' + str(best_mean_mae))
print(best_pdqPDQ)
plt.plot(data_test,color='blue')
plt.plot(predictions_df, color='red')
plt.show()

# best range(0,2):
# Best MAE = 0.2524024604742092
# (1, 0, 1, 1, 1, 1)
# Wall time: 14min 50s

# best range(0,2):

# Best MAE = 0.22780663319275937
# (1, 0, 2, 0, 1, 2)
# Wall time: 2h 6min 26s


# In[58]:


best_pdqPDQ = (1, 0, 2, 0, 1, 2)


# In[59]:


from sklearn.metrics import mean_absolute_error
from statsmodels.tsa.statespace.sarimax import SARIMAX


start_time = timeit.default_timer()

warnings.filterwarnings("ignore") # specify to ignore warning messages

print("-------")

maes = []

for train_index, test_index in tscv_diff.split(ts_diff):
    if train_index.size > 300:

        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

        # build model
        model = SARIMAX(cv_train, 
                order=best_pdqPDQ[:3], 
                seasonal_order=(best_pdqPDQ[3:]+(12,)))
        model_fit = model.fit()

        # make predictions
        predictions =  model_fit.predict(start=len(cv_train), end=len(cv_train)+cv_test.size-1, dynamic=False)
        prediction_values = predictions.values
        true_values = cv_test.values

        # error calc
    #     print(true_values)
    #     print(predictions.values)
        maes.append(mean_absolute_error(true_values, prediction_values))
        print("I",end="")



time_SARIMA = timeit.default_timer() - start_time
mae_mean = np.mean(maes)
MAE_SARIMA = mae_mean
last_MAE_SARIMA = maes[-1]
last_prediction_SARIMA = prediction_values


print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_SARIMA)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_SARIMA)
print('Execution time: %.3f seconds' % time_SARIMA)

reverted_prediction_values = revert_diff(last_prediction_SARIMA, ts[:-5])
full_graph(reverted_prediction_values, ts[:-5],'Last 2 year prediction SARIMAX')
print(maes)


# ## Seasonal differencing

# ### Determine hyperparameters

# In[79]:


# SARIMAX

import itertools
import warnings
import sys
from statsmodels.tsa.statespace.sarimax import SARIMAX


# Define the p, d and q parameters to take any value between 0 and 2
p = q = P = D = Q = range(0, 3)
d = D = range(0, 2)

# Generate all different combinations of p, q and q triplets
pdqPDQ = list(itertools.product(p, d, q , P, D, Q))
best_pdqPDQ = pdqPDQ
best_mean_mae = np.inf
warnings.filterwarnings("ignore") # specify to ignore warning messages
for param in pdqPDQ:
    print(param)
    try:   # some parametercombinations might lead to crash, so catch exceptions and continue
        maes = []
        for train_index, test_index in tscv_diff_seasonal.split(ts_diff_seasonal):
            if train_index.size > 300:
                # initialize cross validation train and test sets
                cv_train, cv_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

                # build model
                model = SARIMAX(cv_train, 
                order=param[:3], 
                seasonal_order=(12,)+param[3:])
                model_fit = model.fit()

                # make predictions
#                 predictions =  model_fit.predict(start=len(cv_train), end=len(cv_train)+cv_test.size-1, dynamic=False)
                predictions =  model_fit.forecast(steps=24)
                prediction_values = predictions.values
                true_values = cv_test.values
                # error calc
                #     print(true_values)
                #     print(predictions.values)
                maes.append(mean_absolute_error(true_values, prediction_values))

        
        mean_mae = np.mean(maes)
        print('MAE: ' + str(mean_mae))    

        if mean_mae < best_mean_mae:
            best_mean_mae = mean_mae
            best_maes = maes
            best_pdqPDQ = param
            best_predictions = prediction_values
    except Exception as e:
        print(e)
        continue

print(best_predictions.size)
print(data_test.index.size)

        
predictions_df = pd.DataFrame(best_predictions).set_index(keys=data_test.index)

# plot
print()
print('Best MAE = ' + str(best_mean_mae))
print(best_pdqPDQ)
plt.plot(data_test,color='blue')
plt.plot(predictions_df, color='red')
plt.show()

# best range(0,2):
# Best MAE = 0.2524024604742092
# (1, 0, 1, 1, 1, 1)
# Wall time: 14min 50s

# best range(0,2):

# Best MAE = 0.22780663319275937
# (1, 0, 2, 0, 1, 2)
# Wall time: 2h 6min 26s


# In[60]:


best_pdqPDQ = (1, 0, 2, 0, 1, 2)


# In[61]:


from sklearn.metrics import mean_absolute_error
from statsmodels.tsa.statespace.sarimax import SARIMAX


start_time = timeit.default_timer()

warnings.filterwarnings("ignore") # specify to ignore warning messages

print("------")

maes = []

for train_index, test_index in tscv_diff_seasonal.split(ts_diff_seasonal):
    if train_index.size > 300:

        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

        # build model
        model = SARIMAX(cv_train, 
                order=best_pdqPDQ[:3], 
                seasonal_order=(best_pdqPDQ[3:]+(12,)))
        model_fit = model.fit()

        # make predictions
        predictions =  model_fit.predict(start=len(cv_train), end=len(cv_train)+cv_test.size-1, dynamic=False)
        prediction_values = predictions.values
        true_values = cv_test.values

        # error calc
    #     print(true_values)
    #     print(predictions.values)
        maes.append(mean_absolute_error(true_values, prediction_values))
        print("I",end="")



time_SARIMA_seasonal = timeit.default_timer() - start_time
mae_mean = np.mean(maes)
MAE_SARIMA_seasonal = mae_mean
last_MAE_SARIMA_seasonal = maes[-1]
last_prediction_SARIMA_seasonal = prediction_values


print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_SARIMA_seasonal)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_SARIMA_seasonal)
print('Execution time: %.3f seconds' % time_SARIMA_seasonal)

reverted_prediction_values = revert_diff_seasonal(last_prediction_SARIMA_seasonal, ts)
full_graph(reverted_prediction_values, ts,'Last 2 year prediction SARIMAX')
print(maes)


# # LSTM

# In[62]:


from keras.layers import Dropout
from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense


# split a univariate sequence into samples
def split_sequence(sequence, n_steps_in, n_steps_out):
    X, y = list(), list()
    for i in range(len(sequence)):
        # find the end of this pattern
        end_ix = i + n_steps_in
        out_end_ix = end_ix + n_steps_out
        
        # check if we are beyond the sequence
        if out_end_ix > len(sequence):
            break
            
        # gather input and output parts of the pattern
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return array(X), array(y)
 
def build_model(raw_seq, n_steps_in, n_steps_out, n_features, n_neurons, dropout, batch_s):
    
    # split into samples
    X, y = split_sequence(raw_seq.values.flatten(), n_steps_in, n_steps_out)
    
    # reshape from [samples, timesteps] into [samples, timesteps, features]
    X = X.reshape((X.shape[0], X.shape[1], n_features))
    
    # define model
    model = Sequential()
    model.add(LSTM(n_neurons, activation='relu'))
    model.add(Dropout(dropout))
    model.add(Dense(n_steps_out))
    model.compile(optimizer='adam', loss='mae')
    
    # fit model
    model.fit(X, y, batch_size=batch_s, epochs=100, verbose=0)
    
    return model


def predict(x_input, model, n_features):
    n_features = 1
    x_input = x_input.reshape((1, n_steps_in, n_features))
    yhat = model.predict(x_input, verbose=0)
    return yhat


# ## Regular differencing 

# In[32]:


import timeit
import tensorflow as tf


start_time = timeit.default_timer()

# Disabled tf warning because of visual clutter
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


# constant variables
n_steps_in = 24
n_steps_out = 24
n_features  = 1
maes = []
global_maes = []

# optimizable variables
n_neurons_array = [1,10,20]
dropout_array = [0,0.99]
batch_size_array = [1,2,8]

# n_neurons_array = [1,20]
# dropout_array = [0]
# batch_size_array = [1,8]



# initialize values
best_MAE = 100
best_n_neurons = 0
best_activation = 'none'
best_dropout = 0
best_batch_size = 0

for n_neurons in n_neurons_array:
    for dropout in dropout_array:
        for batch_size in batch_size_array:
            print("-----")
#             tscv = TimeSeriesSplit(n_splits = 17)
            for train_index, test_index in tscv_diff.split(ts_diff): 
                if train_index.size > 300:  
                    # initialize cross validation train and test sets
                    y_train, y_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

                    # build model
                    lstm_model = build_model(y_train, n_steps_in, n_steps_out, n_features, n_neurons, dropout, batch_size)

                    # make predictions
                    x_input = array(y_test)
                    y_predicted = predict(x_input, lstm_model, n_features).flatten()
                    y_actual = y_test.values

                    # error calc
                    maes.append(mean_absolute_error(y_actual, y_predicted))

                    print("I",end="")

                    # last actual prediction 
                    last_prediction_LSTM = y_predicted

            time_LSTM = timeit.default_timer() - start_time
            MAE_LSTM = np.mean(maes)
            last_MAE_LSTM = maes[-1]
            global_maes.append(MAE_LSTM)

            if best_MAE > MAE_LSTM:
                best_n_neurons = n_neurons
                best_dropout = dropout
                best_batch_size = batch_size
                best_MAE = MAE_LSTM

            print()
            print(n_neurons)
            print(dropout)
            print(batch_size)
            print(MAE_LSTM)
            print()    

print('Best:')
print('N neurons')
print(best_n_neurons)
print('Dropout rate')
print(best_dropout)
print('Batch size')
print(best_batch_size)
print('MAE')
print(best_MAE)
plt.bar(range(0,len(global_maes)), global_maes)


# In[63]:


best_n_neurons, best_dropout, best_batch_size = 1, 0, 1 # actual best params


# In[64]:


import timeit
import tensorflow as tf


start_time = timeit.default_timer()

# Disabled tf warning because of visual clutter
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


# constant variables
n_steps_in = 24
n_steps_out = 24
n_features  = 1
maes = []
global_maes = []

print("------")
tscv = TimeSeriesSplit(n_splits = 18)
for train_index, test_index in tscv.split(ts_diff): 
    if train_index.size > 300:  
        # initialize cross validation train and test sets
        y_train, y_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

        # build model
        lstm_model = build_model(y_train, n_steps_in, n_steps_out, n_features, best_n_neurons, best_dropout, best_batch_size)

        # make predictions
        x_input = array(y_test)
        y_predicted = predict(x_input, lstm_model, n_features).flatten()
        y_actual = y_test.values

        # error calc
        maes.append(mean_absolute_error(y_actual, y_predicted))

        print("I",end="")

time_LSTM = timeit.default_timer() - start_time
MAE_LSTM = np.mean(maes)
last_MAE_LSTM = maes[-1]
global_maes.append(MAE_LSTM)
last_prediction_LSTM = y_predicted

# print('Best:')
# print('N neurons')
# print(best_n_neurons)
# print('Dropout rate')
# print(best_dropout)
# print('Batch size')
# print(best_batch_size)
# print('MAE')
# print(best_MAE)
# plt.bar(range(0,len(global_maes)), global_maes)

# time_ARIMA = timeit.default_timer() - start_time
# mae_mean = np.mean(maes)
# MAE_ARIMA = mae_mean
# last_MAE_ARIMA = maes[-1]

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_LSTM)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_LSTM)
print('Execution time: %.3f seconds' % time_LSTM)

reverted_prediction_values = revert_diff_seasonal(last_prediction_LSTM, ts)
full_graph(reverted_prediction_values, ts,'Last 2 year prediction LSTM random walk differencing')

print(maes)


# ## Seasonal differencing

# In[99]:


# initialize values
best_n_neurons = 1
best_dropout = 0
best_batch_size = 1


# In[100]:


import timeit
import tensorflow as tf


start_time = timeit.default_timer()

# Disabled tf warning because of visual clutter
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


# constant variables
n_steps_in = 24
n_steps_out = 24
n_features  = 1
maes = []
global_maes = []

# optimizable variables
n_neurons_array = [1,5,10,20]
dropout_array = [0,0.5,0.99]
batch_size_array = [1,2,4,8]
## set#2
# n_neurons_array = [1,20]2
# dropout_array = [0]
# batch_size_array = [1,8]



# initialize values
best_MAE = 100
best_n_neurons = 0
best_activation = 'none'
best_dropout = 0
best_batch_size = 0

for n_neurons in n_neurons_array:
    for dropout in dropout_array:
        for batch_size in batch_size_array:
            print("------")
#             tscv = TimeSeriesSplit(n_splits = 17)
            for train_index, test_index in tscv_diff.split(ts_diff_seasonal): 
                if train_index.size > 300:  
                    # initialize cross validation train and test sets
                    y_train, y_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

                    # build model
                    lstm_model = build_model(y_train, n_steps_in, n_steps_out, n_features, n_neurons, dropout, batch_size)

                    # make predictions
                    x_input = array(y_test)
                    y_predicted = predict(x_input, lstm_model, n_features).flatten()
                    y_actual = y_test.values

                    # error calc
                    maes.append(mean_absolute_error(y_actual, y_predicted))

                    print("I",end="")

                    # last actual prediction 
                    last_prediction_LSTM = y_predicted

            time_LSTM = timeit.default_timer() - start_time
            MAE_LSTM = np.mean(maes)
            last_MAE_LSTM = maes[-1]
            global_maes.append(MAE_LSTM)

            if best_MAE > MAE_LSTM:
                best_n_neurons = n_neurons
                best_dropout = dropout
                best_batch_size = batch_size
                best_MAE = MAE_LSTM

            print()
            print(n_neurons)
            print(dropout)
            print(batch_size)
            print(MAE_LSTM)
            print()    

print('Best:')
print('N neurons')
print(best_n_neurons)
print('Dropout rate')
print(best_dropout)
print('Batch size')
print(best_batch_size)
print('MAE')
print(best_MAE)
plt.bar(range(0,len(global_maes)), global_maes)


# In[65]:


best_n_neurons, best_dropout, best_batch_size = 1, 0.99, 8 # ran for 5 hours


# In[66]:


import timeit
import tensorflow as tf


start_time = timeit.default_timer()

# Disabled tf warning because of visual clutter
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


# constant variables
n_steps_in = 24
n_steps_out = 24
n_features  = 1
maes = []
global_maes = []

print("------")
tscv = TimeSeriesSplit(n_splits = 18)
for train_index, test_index in tscv.split(ts_diff_seasonal): 
    if train_index.size > 300:  
        # initialize cross validation train and test sets
        y_train, y_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

        # build model
        lstm_model = build_model(y_train, n_steps_in, n_steps_out, n_features, best_n_neurons, best_dropout, best_batch_size)

        # make predictions
        x_input = array(y_test)
        y_predicted = predict(x_input, lstm_model, n_features).flatten()
        y_actual = y_test.values

        # error calc
        maes.append(mean_absolute_error(y_actual, y_predicted))

        print("I",end="")

        

time_LSTM_seasonal = timeit.default_timer() - start_time
MAE_LSTM_seasonal = np.mean(maes)
last_MAE_LSTM_seasonal = maes[-1]
global_maes.append(MAE_LSTM_seasonal)
last_prediction_LSTM_seasonal = y_predicted
# print('Best:')
# print('N neurons')
# print(best_n_neurons)
# print('Dropout rate')
# print(best_dropout)
# print('Batch size')
# print(best_batch_size)
# print('MAE')
# print(best_MAE)
# plt.bar(range(0,len(global_maes)), global_maes)

# time_ARIMA = timeit.default_timer() - start_time
# mae_mean = np.mean(maes)
# MAE_ARIMA = mae_mean
# last_MAE_ARIMA = maes[-1]

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_LSTM_seasonal)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_LSTM_seasonal)
print('Execution time: %.3f seconds' % time_LSTM_seasonal)

reverted_prediction_values = revert_diff_seasonal(last_prediction_LSTM_seasonal, ts)
full_graph(reverted_prediction_values, ts,'Last 2 year prediction LSTM Seasonal')

print(maes)


# # Prophet

# In[67]:


ts_diff.reset_index()


# In[68]:


# formatting dataframe
ts_formated_prophet = ts_diff.reset_index().rename(columns = {'date' : 'ds', 'ice_extent' : 'y'})
ts_formated_prophet['ds'] = pd.DataFrame(pd.to_datetime(ts_formated_prophet['ds'].astype(str), format='%Y-%m-%d'))


# In[69]:


# initialize TimeSeriesSplit object
tscv_prophet = TimeSeriesSplit(n_splits = 18)

# loop trough all split time series that have a trainingsset with more than 20 values
for train_index, test_index in tscv_prophet.split(ts_formated_prophet):
    if train_index.size > 300:

        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]
        
         # visiualize cross_validation structure for reference
        print("TRAIN:", train_index.size)
        print("TEST:", test_index.size)
        print()


# In[39]:


# Python
import itertools
import numpy as np
import pandas as pd
from fbprophet import Prophet
from sklearn.metrics import mean_absolute_error


# define dataframe
df = ts_formated_prophet

param_grid = {  
    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5, 0.75, 1],
    'seasonality_prior_scale': [0.001, 0.01, 0.1, 1, 2, 5, 10],
}

# Generate all combinations of parameters
all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]

# initialize variables
maes = []  
global_maes = []
best_MAE_prophet = np.inf

# Use cross validation to evaluate all parameters
for params in all_params:

    # loop trough all split time series that have a trainingsset with more than 20 values
    for train_index, test_index in tscv_prophet.split(ts_formated_prophet):    
        if train_index.size > 300:  
            
            # initialize cross validation train and test sets
            train  = ts_formated_prophet.iloc[train_index]
            y_test = ts_formated_prophet.iloc[test_index][['y']].values.flatten()
            X_test = ts_formated_prophet.iloc[test_index][['ds']]

            # Fit model with given params
            model = Prophet(**params, weekly_seasonality=False, daily_seasonality=False)
            model = model.fit(train)
            
            # make predictions
            forecast = model.predict(X_test)
            y_pred = forecast['yhat'].values
            
            # last actual prediction 
            last_prediction_prophet = y_pred
            
            # error calculation this part of the cross validation
            maes.append(mean_absolute_error(y_test, y_pred))
            
    # error calculation for this parameter combination
    MAE_prophet = np.mean(maes)
    last_MAE_prophet = maes[-1]
    global_maes.append(MAE_prophet)
    
    # logging
    print('changepoint_prior_scale: ' + str(params['changepoint_prior_scale']))
    print('seasonality_prior_scale: ' + str(params['seasonality_prior_scale']))
    print(MAE_prophet)
    
    # store parameters resulting in the lowest mean MAE
    if best_MAE_prophet > MAE_prophet:
        best_params = params
        best_MAE_prophet = MAE_prophet

# log optimal result          
print('changepoint_prior_scale: ' + str(best_params['changepoint_prior_scale']))
print('seasonality_prior_scale: ' + str(best_params['seasonality_prior_scale']))
print(best_MAE_prophet)
            


# In[77]:


best_params = {'changepoint_prior_scale': 0.001, 'seasonality_prior_scale': 10}


# In[78]:


from fbprophet import Prophet
# Disabled tf warning because of clutter
warnings.filterwarnings("ignore") # specify to ignore warning messages

start_time = timeit.default_timer()

# initialize variables
maes = []

for train_index, test_index in tscv_prophet.split(ts_formated_prophet):
    if train_index.size > 300:  
        
        # initialize cross validation train and test sets
        train  = ts_formated_prophet.iloc[train_index]
        y_test = ts_formated_prophet.iloc[test_index][['y']].values.flatten()
        X_test = ts_formated_prophet.iloc[test_index][['ds']]

        # build model
        model = Prophet(**best_params, weekly_seasonality=False, daily_seasonality=False)
        model.fit(train)

        # make predictions
        forecast = model.predict(X_test)
        y_pred = forecast['yhat'].values

        # error calc
        maes.append(mean_absolute_error(y_test, y_pred))

        


# store results
time_Prophet = timeit.default_timer() - start_time
MAE_Prophet = np.mean(maes)
last_MAE_Prophet = maes[-1]
last_prediction_prophet = y_pred

# visualize results
print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_Prophet)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_Prophet)
print('Execution time: %.3f seconds' % time_Prophet)

reverted_prediction_values = revert_diff_seasonal(last_prediction_prophet, ts)
full_graph(reverted_prediction_values, ts, "Last 2 year prediction prophet")
print('Mean average errors')
print(maes)


# In[ ]:


Mean MAE: 0.250 x 1 000 000 km


# # Evaluation

# In[79]:


# formatting
results = [[MAE_ARIMA, time_ARIMA, last_MAE_ARIMA],
           [MAE_ARIMA_seasonal, time_ARIMA_seasonal, last_MAE_ARIMA_seasonal],
           [MAE_SARIMA, time_SARIMA, last_MAE_SARIMA],
           [MAE_SARIMA_seasonal, time_SARIMA_seasonal, last_MAE_SARIMA_seasonal],
           [MAE_LSTM, time_LSTM, last_MAE_LSTM],
           [MAE_LSTM_seasonal, time_LSTM_seasonal, last_MAE_LSTM_seasonal],
           [MAE_Prophet, time_Prophet, last_MAE_Prophet]]

# display results
results = pd.DataFrame(results, columns=['Mean MAE (x 1 000 000 km\u00b2)','Execution time (s)','Last MAE (x 1 000 000 km\u00b2)']
             ,index=['ARIMA','ARIMA_seasonal_differencing','SARIMA','SARIMA_seasonal_differncing','LSTM','LSTM_seasonal_differencing','Prophet']).round(decimals=3)
results


# In[84]:


reverted_prediction_values = revert_diff(last_prediction_ARIMA, ts[:-5])
full_graph(reverted_prediction_values, ts[:-5],'Last prediction ARIMA')

reverted_prediction_values = revert_diff_seasonal(last_prediction_ARIMA_seasonal, ts)
full_graph(reverted_prediction_values, ts,'Last prediction ARIMA with seasonal differencing')

reverted_prediction_values = revert_diff(last_prediction_SARIMA, ts[:-5])
full_graph(reverted_prediction_values, ts[:-5],'Last prediction SARIMAX')

reverted_prediction_values = revert_diff_seasonal(last_prediction_SARIMA_seasonal, ts)
full_graph(reverted_prediction_values, ts,'Last prediction SARIMAX')


# In[83]:



reverted_prediction_values = revert_diff_seasonal(last_prediction_LSTM, ts)
full_graph(reverted_prediction_values, ts,'Last prediction LSTM')

reverted_prediction_values = revert_diff_seasonal(last_prediction_LSTM_seasonal, ts)
full_graph(reverted_prediction_values, ts,'Last prediction LSTM Seasonal')

reverted_prediction_values = revert_diff_seasonal(last_prediction_prophet, ts)
full_graph(reverted_prediction_values, ts, "Last 2 year prediction Prophet")



\end{minted}

\section{Broncode voor het vergelijken van ARIMA, LSTM en Prophet bij multivariate, niet-seizoensgebonden tijdreeksen}  % The \section*{} command stops section numbering
\captionof{listing}{Broncode voor het vergelijken van ARIMA, LSTM en Prophet bij multivariate, niet-seizoensgebonden tijdreeksen}
\begin{minted}[
frame=lines,
framesep=2mm,
fontsize=\footnotesize,
linenos,breaklines
]{python}

#!/usr/bin/env python
# coding: utf-8

# # Imports

# In[1]:


import numpy as np
import pandas as pd
# matplotlib is the Python library for drawing diagrams
import matplotlib.pylab as plt
get_ipython().run_line_magic('matplotlib', 'inline')
# set the size of the diagrams
from matplotlib.pylab import rcParams
rcParams['figure.figsize'] = 15,5
from math import sqrt
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import TimeSeriesSplit


# In[2]:


def test_stationarity(timeseries, title):
    
    #Determing rolling statistics
    rolmean = timeseries.rolling(12).mean()
#     rolstd = timeseries.rolling(24).std()

    #Plot rolling statistics:
    orig = plt.plot(timeseries, color='blue',label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
#     std = plt.plot(rolstd, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation from column: ' + title)
    plt.show(block=False)
    
def full_graph(predicted_diff, title):
    predictionsArray = np.asarray(revert_diff(predicted_diff, ts_ie))
    zerosArray = np.zeros(ts_ie.values.size-len(predictionsArray.flatten()))
    cleanPrediction = pd.Series(np.concatenate((zerosArray,predictionsArray))).replace(0,np.NaN)
    
    # plot
    plt.title(title)
    plt.plot(ts_ie.values,marker='o', color='blue',label='Actual values')
    plt.plot(cleanPrediction,marker='o', color='red',label='Last 4 year prediction')
    plt.ylim([0,15])
    plt.legend()

    plt.show()
    
def revert_diff(predicted_diff, og_data):
    last_value = og_data.iloc[-predicted_diff.size-1][0]
    predicted_actual = np.array([])
    for value_diff in predicted_diff:
        actual_value = last_value + value_diff
        predicted_actual = np.append(predicted_actual, actual_value)
        last_value = actual_value
    return predicted_actual


# ## Dataprep

# In[3]:


ts = pd.read_csv('./data/dataframe_yearly.csv', index_col=0).reset_index()
ts.rename(columns={'Year':'year'}, inplace=True)
ts.set_index('year', inplace=True)


# In[4]:


ts_ie = ts[['ice_extent']]


# In[5]:


ts


# In[6]:


plt.title('Temperature')
plt.plot(ts.iloc[:,0], label='temperature')
plt.ylabel('C')
plt.show()
plt.title('Ice extent')
plt.ylabel('x 1 000 000 km\u00b2')
plt.plot(ts.iloc[:,1], label='ice extent')


# In[7]:


test_stationarity(ts[['ice_extent']], 'ice_extent')


# ### Differencing

# In[8]:


ts_diff = ts - ts.shift(1)
ts_diff = ts_diff.dropna()
test_stationarity(ts_diff[['ice_extent']], 'ice_extent')
test_stationarity(ts_diff[['mean_temp']], 'mean_temp')


# Datasets are stationary now

# # Cross validation setup

# In[9]:


tscv = TimeSeriesSplit(n_splits = 8)
dataset = ts_diff

for train_index, test_index in tscv.split(dataset):
    if train_index.size > 20:

        # initialize cross validation train and test sets
        cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]

        print("TRAIN:", train_index.size) # visiualize cross_validation structure for reference
        print("TEST:", test_index.size)
        print()


# # VARMAX

# In[10]:


from statsmodels.tsa.statespace.varmax import VARMAX
import itertools
import warnings
import sys
from sklearn.metrics import mean_absolute_error



# Define the p, d and q parameters to take any value between 0 and 2
p = q = range(0, 5)

# Generate all different combinations of p, q and q triplets
pq = list(itertools.product(p, q))
best_pq = pq
best_mean_mae = np.inf
warnings.filterwarnings("ignore") # specify to ignore warning messages
for param in pq:
    print(param)
    try:   # some parametercombinations might lead to crash, so catch exceptions and continue
        maes = []
        for train_index, test_index in tscv.split(dataset):
            if train_index.size > 20:
                # initialize cross validation train and test sets
                cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]

                # build model
                model = VARMAX(cv_train, order=(param))
                model_fit = model.fit()

                # make predictions
                predictions =  model_fit.forecast(steps=4, dynamic=False)
                prediction_values = predictions[['ice_extent']].values
                true_values = cv_test[['ice_extent']].values
                # error calc
                maes.append(mean_absolute_error(true_values, prediction_values))

        
        mean_mae = np.mean(maes)
        print('MAE: ' + str(mean_mae))    

        if mean_mae < best_mean_mae:
            best_mean_mae = mean_mae
            best_maes = maes
            best_pq = param
            best_predictions = prediction_values
    except Exception as e:
        print(e)
        continue
   
# plot
print()
print('Best MAE = ' + str(best_mean_mae))
print(best_pq)

# # best range(0,5)
# Best MAE = 0.15358394799986985
# (3, 3)
# Wall time: 9min 27s


# In[57]:


best_pq = (3,3)


# In[58]:


from statsmodels.tsa.statespace.varmax import VARMAX
from sklearn.metrics import mean_absolute_error
import timeit
import warnings


start_time = timeit.default_timer()

warnings.filterwarnings("ignore") # specify to ignore warning messages

print("----")

maes = []

for train_index, test_index in tscv.split(dataset):
    if train_index.size > 20:
        # initialize cross validation train and test sets
        cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]

        # build model
        model = VARMAX(cv_train, order=(best_pq))
        model_fit = model.fit()

        # make predictions
        predictions =  model_fit.forecast(steps=4, dynamic=False)
        prediction_values = predictions[['ice_extent']].values
        true_values = cv_test[['ice_extent']].values
        # error calc
        maes.append(mean_absolute_error(true_values, prediction_values))

        print("I",end="")
    

time_VARMAX = timeit.default_timer() - start_time
mae_mean = np.mean(maes)
MAE_VARMAX = mae_mean
last_MAE_VARMAX = maes[-1]
last_predictions_VARMAX = prediction_values

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_VARMAX)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_VARMAX)
print('Execution time: %.3f seconds' % time_VARMAX)
full_graph(last_predictions_VARMAX, 'Last prediction VARMAX')
print(maes)


# # LSTM

# In[39]:


# multivariate multi-step encoder-decoder lstm example
from numpy import array
from numpy import hstack
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
from keras.layers import RepeatVector
from keras.layers import TimeDistributed
import warnings

warnings.filterwarnings("ignore") # specify to ignore warning messages


# split a multivariate sequence into samples
def split_sequences(sequences, n_steps_in, n_steps_out):
	X, y = list(), list()
	for i in range(len(sequences)):
		# find the end of this pattern
		end_ix = i + n_steps_in
		out_end_ix = end_ix + n_steps_out
		# check if we are beyond the dataset
		if out_end_ix > len(sequences):
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]
		X.append(seq_x)
		y.append(seq_y)
	return array(X), array(y)

def predict_LSTM(train, test, n_neurons, n_epochs):
    test['sum'] = test['mean_temp'] + test['ice_extent']


    # define input sequence
    in_seq1 = train.values[:,0]
    in_seq2 = train.values[:,1]
    out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])

    # convert to [rows, columns] structure
    in_seq1 = in_seq1.reshape((len(in_seq1), 1))
    in_seq2 = in_seq2.reshape((len(in_seq2), 1))
    out_seq = out_seq.reshape((len(out_seq), 1))
    
    # horizontally stack columns
    dataset = hstack((in_seq1, in_seq2, out_seq))
    
    # choose a number of time steps
    n_steps_in, n_steps_out = 4, 4
    
    # covert into input/output
    X, y = split_sequences(dataset, n_steps_in, n_steps_out)
    
    # the dataset knows the number of features, e.g. 2
    n_features = X.shape[2]
    
    # define model
    model = Sequential()
    model.add(LSTM(n_neurons, activation='relu', input_shape=(n_steps_in, n_features)))
    model.add(RepeatVector(n_steps_out))
    model.add(LSTM(n_neurons, activation='relu', return_sequences=True))
    model.add(TimeDistributed(Dense(n_features)))
    model.compile(optimizer='adam', loss='mae')
    
    # fit model
    model.fit(X, y, epochs=n_epochs, verbose=0)
    
    # demonstrate prediction
    x_input = test.values
    x_input = x_input.reshape((1, n_steps_in, n_features))
    yhat = model.predict(x_input, verbose=0)
    return yhat
    


# In[109]:


from statsmodels.tsa.statespace.varmax import VARMAX
from sklearn.metrics import mean_absolute_error
import timeit
import tensorflow as tf

start_time = timeit.default_timer()

# warnings.filterwarnings("ignore") # specify to ignore warning messages
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

maes = []
global_maes = []
best_MAE = np.inf


n_neurons_array = [1,5,10,20]
n_epochs_array = [100,200,300]

print("----")

maes = []
for n_neurons in n_neurons_array:
    for n_epochs in n_epochs_array:
        for train_index, test_index in tscv.split(dataset):
            if train_index.size > 20:
                # initialize cross validation train and test sets
                cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]

                yhat = predict_LSTM(cv_train, cv_test, n_neurons, n_epochs)


                prediction_values = yhat[0][:,1]
                true_values = cv_test[['ice_extent']].values

                # error calc
                maes.append(mean_absolute_error(true_values, prediction_values))

                print("I",end="")
        time_LSTM = timeit.default_timer() - start_time
        MAE_LSTM = np.mean(maes)
        last_MAE_LSTM = maes[-1]
        global_maes.append(MAE_LSTM)

        if best_MAE > MAE_LSTM:
            best_n_neurons = n_neurons
            best_n_epochs = n_epochs
            best_MAE = MAE_LSTM

        print()
        print(n_neurons)
        print(n_epochs)
        print(MAE_LSTM)
        print()    

print('Best:')
print('N neurons')
print(best_n_neurons)
print('Epochs size')
print(best_n_epochs)
print('MAE')
print(best_MAE)


# In[41]:


best_n_neurons, best_n_epochs = 1, 200


# In[42]:


from sklearn.metrics import mean_absolute_error
import timeit
import tensorflow as tf

start_time = timeit.default_timer()

# warnings.filterwarnings("ignore") # specify to ignore warning messages
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


print("----")

maes = []

for train_index, test_index in tscv.split(ts_diff):
    if train_index.size > 20:

        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff.iloc[train_index], ts_diff.iloc[test_index]

        yhat = predict_LSTM(cv_train, cv_test, best_n_neurons, best_n_epochs)


        prediction_values = yhat[0][:,1]
        true_values = cv_test[['ice_extent']].values

        # error calc
        maes.append(mean_absolute_error(true_values, prediction_values))

        print("I",end="")
    

time_LSTM = timeit.default_timer() - start_time
mae_mean = np.mean(maes)
MAE_LSTM = mae_mean
last_MAE_LSTM = maes[-1]
last_predictions_LSTM = prediction_values

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_LSTM)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_LSTM)
print('Execution time: %.3f seconds' % time_LSTM)
full_graph(last_predictions_LSTM, 'Last prediction LSTM')
print(maes)


# # Prophet

# In[ ]:


# formatting dataframe
ts_formated_prophet = ts_diff.reset_index().rename(columns = {'year' : 'ds', 'ice_extent' : 'y'})
ts_formated_prophet['ds'] = pd.DataFrame(pd.to_datetime(ts_formated_prophet['ds'].astype(str), format='%Y'))


# In[ ]:


from fbprophet import Prophet
m = Prophet()
m.add_regressor('mean_temp')
m.fit(df_train)


# In[ ]:


# Python
import itertools
import numpy as np
import pandas as pd

warnings.filterwarnings("ignore") # specify to ignore warning messages

# define dataframe
df = ts_formated_prophet

param_grid = {  
    'changepoint_prior_scale': [0.001, 0.01, 0.1, 1, 2, 5, 10, 15, 20, 25],
}

# Generate all combinations of parameters
all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]

# initialize variables
maes = []  
global_maes = []
best_MAE_prophet = np.inf

# Use cross validation to evaluate all parameters
for params in all_params:

    # loop trough all split time series that have a trainingsset with more than 20 values
    for train_index, test_index in tscv.split(ts_formated_prophet):    
        if train_index.size > 20:  

            # initialize cross validation train and test sets
            train  = ts_formated_prophet.iloc[train_index]
            y_test = ts_formated_prophet.iloc[test_index][['y']].values.flatten()
            X_test = ts_formated_prophet.iloc[test_index][['ds','mean_temp']]

            # Fit model with given params
            model = Prophet(weekly_seasonality=False, daily_seasonality=False)
            model = model.add_regressor('mean_temp')
            model = model.fit(train)

            # make predictions
            forecast = model.predict(X_test)
            y_pred = forecast['yhat'].values

            # last actual prediction 
            last_prediction_prophet = y_pred

            # error calculation this part of the cross validation
            maes.append(mean_absolute_error(y_test, y_pred))
    
    # error calculation for this parameter combination
    MAE_prophet = np.mean(maes)
    last_MAE_prophet = maes[-1]
    global_maes.append(MAE_prophet)
    
    # logging
    print('changepoint_prior_scale: ' + str(params['changepoint_prior_scale']))
    
    # store parameters resulting in the lowest mean MAE
    if best_MAE_prophet > MAE_prophet:
        best_params = params
        best_MAE_prophet = MAE_prophet

# log optimal result          
print('changepoint_prior_scale: ' + str(best_params['changepoint_prior_scale']))
print(best_MAE_prophet)


# In[ ]:





# In[57]:


maes = []
global_maes = []

from sklearn.metrics import mean_absolute_error

# loop trough all split time series that have a trainingsset with more than 20 values
for train_index, test_index in tscv.split(ts_formated_prophet):    
    if train_index.size > 20:  

        # initialize cross validation train and test sets
        train  = ts_formated_prophet.iloc[train_index]
        y_test = ts_formated_prophet.iloc[test_index][['y']].values.flatten()
        X_test = ts_formated_prophet.iloc[test_index][['ds','mean_temp']]

        # Fit model with given params
        model = Prophet(weekly_seasonality=False, daily_seasonality=False)
        model = model.add_regressor('mean_temp')
        model = model.fit(train)

        # make predictions
        forecast = model.predict(X_test)
        y_pred = forecast['yhat'].values

        # last actual prediction 
        last_prediction_prophet = y_pred

        # error calculation this part of the cross validation
        maes.append(mean_absolute_error(y_test, y_pred))

# error calculation for this parameter combination
MAE_prophet = np.mean(maes)
last_MAE_prophet = maes[-1]
global_maes.append(MAE_prophet)
print(np.mean(maes))


# In[34]:


# formatting dataframe
ts_formated_prophet = ts_diff.reset_index().rename(columns = {'year' : 'ds', 'ice_extent' : 'y'})
ts_formated_prophet['ds'] = pd.DataFrame(pd.to_datetime(ts_formated_prophet['ds'].astype(str), format='%Y'))


# In[39]:


df_train = ts_formated_prophet.iloc[:-4]
df_test  = ts_formated_prophet.iloc[-4:]


# In[40]:


df_train.head()


# In[41]:


from fbprophet import Prophet
m = Prophet()
m.add_regressor('mean_temp')
m.fit(df_train)


# In[43]:


forecast = m.predict(df_test.drop(columns="y"))
forecast.set_index('ds')[['yhat']]


# In[ ]:


# example


# In[2]:


import pandas as pd
df = pd.DataFrame(pd.date_range(start="2019-09-01", end="2019-09-30", freq='D', name='ds'))
df["y"] = range(1,31)
df["add1"] = range(101,131)
df["add2"] = range(201,231)
df.head()


# In[3]:


df_train = df.loc[df["ds"]<"2019-09-21"]
df_test  = df.loc[df["ds"]>="2019-09-21"]


# In[4]:


from fbprophet import Prophet
m = Prophet()
m.add_regressor('add1')
m.add_regressor('add2')
m.fit(df_train)


# In[10]:


forecast = m.predict(df_test.drop(columns="y"))
forecast.set_index('ds')[['yhat']]


# ### Evaluation

# In[112]:


# formatting
results = [[MAE_VARMAX, time_VARMAX, last_MAE_VARMAX],
           [MAE_LSTM, time_LSTM, last_MAE_LSTM]]

# display results
results = pd.DataFrame(results, columns=['Mean MAE (x 1 000 000 km\u00b2)','Execution time (s)','Last MAE (x 1 000 000 km\u00b2)']
             ,index=['VARMAX','LSTM']).round(decimals=3)
results


# In[65]:


full_graph(last_predictions_VARMAX, 'Last prediction VARMAX')
full_graph(last_predictions_LSTM, 'Last prediction LSTM')

\end{minted}

\section{Broncode voor het vergelijken van ARIMA, LSTM en Prophet bij multivariate, seizoensgebonden tijdreeksen}  % The \section*{} command stops section numbering
\captionof{listing}{Broncode voor het vergelijken van ARIMA, LSTM en Prophet bij multivariate, seizoensgebonden tijdreeksen}
\begin{minted}[
frame=lines,
framesep=2mm,
fontsize=\footnotesize,
linenos,breaklines
]{python}

#!/usr/bin/env python
# coding: utf-8

# In[54]:


import pandas as pd
import numpy as np
# matplotlib is the Python library for drawing diagrams
import matplotlib.pylab as plt
get_ipython().run_line_magic('matplotlib', 'inline')
# set the size of the diagrams
from matplotlib.pylab import rcParams
rcParams['figure.figsize'] = 15,5
from sklearn.model_selection import TimeSeriesSplit


# # General functions

# In[100]:


reverted_prediction_values


# In[104]:


ts[['ice_extent']].max()


# In[119]:





# In[112]:


plt.plot(last_predictions_VARMAX_seasonal)


# In[162]:



# reverted_prediction_values = revert_diff_seasonal(last_predictions_VARMAX_seasonal, ts[['ice_extent']])
full_graph_seasonal(last_predictions_VARMAX_seasonal, 'Last 2 year prediction ARIMA with seasonal differencing')


# In[171]:


def test_stationarity(timeseries, title):
    
    #Determing rolling statistics
    rolmean = timeseries.rolling(12).mean()
#     rolstd = timeseries.rolling(24).std()

    #Plot rolling statistics:
    orig = plt.plot(timeseries, color='blue',label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
#     std = plt.plot(rolstd, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation from column: ' + title)
    plt.show(block=False)
    
def full_graph(predicted_diff, title):
    dataset_ie = ts[['ice_extent']][:-5]
    predictionsArray = np.asarray(revert_diff(predicted_diff, dataset_ie))
    zerosArray = np.zeros(dataset_ie.values.size-len(predictionsArray.flatten()))
    cleanPrediction = pd.Series(np.concatenate((zerosArray,predictionsArray))).replace(0,np.NaN)
    
    # plot
    plt.title(title)
    plt.plot(dataset_ie.index, dataset_ie.values,marker='o', color='blue',label='Actual values')
    plt.plot(dataset_ie.index, cleanPrediction,marker='o', color='red',label='Last 2 year prediction')
    plt.ylim([0,20])
    plt.legend()

    plt.show()
    
def full_graph_seasonal(predicted, title):
    predicted = predicted.flatten() + ts[['ice_extent']].values.flatten()[-48:-24]
    zerosArray = np.zeros(ts[['ice_extent']].values.size-len(predicted.flatten()))
    cleanPrediction = pd.Series(np.concatenate((zerosArray,predicted.flatten()))).replace(0,np.NaN)
    
    # plot
    plt.title(title)
    plt.plot(ts.index, ts[['ice_extent']].values,marker='o', color='blue',label='Actual values')
    plt.plot(ts.index, cleanPrediction,marker='o', color='red',label='Last 2 year prediction')
    plt.ylim([0,20])
    plt.legend()

    plt.show()
    
def revert_diff(predicted_diff, og_data):
    last_value = og_data.iloc[-predicted_diff.size-1][0]
    predicted_actual = np.array([])
    for value_diff in predicted_diff:
        actual_value = last_value + value_diff
        predicted_actual = np.append(predicted_actual, actual_value)
        last_value = actual_value
    return predicted_actual


# # Dataprep

# In[56]:


ts = pd.read_csv('./data/dataframe_monthly.csv', index_col=0).reset_index()


# In[57]:


ts


# In[58]:


ts['date'] = pd.to_datetime(ts['Month'].astype(str) + ts['Year'].astype(str), format='%m%Y', errors='ignore')


# In[59]:


ts


# In[60]:


ts = ts[['date','ice_extent','mean_temp']]
ts.set_index('date', inplace=True)
plt.plot(ts[['ice_extent']])
plt.title('ice_extent')
plt.show()
plt.plot(ts[['mean_temp']])
plt.title('mean_temp')


# In[61]:


test_stationarity(ts[['ice_extent']], 'ice_extent')
test_stationarity(ts[['mean_temp']], 'mean_temp')


# # Differencing

# In[62]:


ts_diff = ts - ts.shift(1)
ts_diff = ts_diff.dropna()
test_stationarity(ts_diff[['ice_extent']], 'ice_extent')
test_stationarity(ts_diff[['mean_temp']], 'mean_temp')


# In[63]:


ts_diff_seasonal = ts - ts.shift(12)
ts_diff_seasonal = ts_diff_seasonal.dropna()
test_stationarity(ts_diff_seasonal[['ice_extent']], 'ice_extent')
test_stationarity(ts_diff_seasonal[['mean_temp']], 'mean_temp')


# In[64]:


tscv = TimeSeriesSplit(n_splits = 18)
dataset = ts_diff[:-5] # need the -5 to get testsets for 24 months/2 years

for train_index, test_index in tscv.split(dataset):
    if train_index.size > 300:

        # initialize cross validation train and test sets
        cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]

        print("TRAIN:", train_index.size) # visiualize cross_validation structure for reference
        print("TEST:", test_index.size)
        print()


# In[65]:


tscv = TimeSeriesSplit(n_splits = 18)

for train_index, test_index in tscv.split(ts_diff_seasonal):
    if train_index.size > 300:

        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

        print("TRAIN:", train_index.size) # visiualize cross_validation structure for reference
        print("TEST:", test_index.size)
        print()


# In[66]:


# og_data = dataset[:-6]
# seasonal_entries = 12
# n_sets = int(og_data.shape[0]/seasonal_entries)
# split_sets = np.array_split(dataset[:-6], n_sets)
# ts_diff = pd.DataFrame(columns = og_data.columns)

# i = 0 

# for year in split_sets[:-1]:
#     ## swap 0 and 1 around
#     # take difference
#     diff = split_sets[i+1].reset_index() - split_sets[i].reset_index()
#     diff = diff.iloc[:,1:]

#     # append to dataframe
#     ts_diff = ts_diff.append(diff[['ice_extent','mean_temp']], ignore_index=True)
#     i = i+1


# In[67]:


# wait 
ts_seasonal_diff = (dataset - dataset.shift(12)).dropna()


# ## VARMAX

# ## Random walk differencing

# In[53]:


from statsmodels.tsa.statespace.varmax import VARMAX
import itertools
import warnings
import sys
from sklearn.metrics import mean_absolute_error



# Define the p, d and q parameters to take any value between 0 and 2
p = q = range(0, 5)

# Generate all different combinations of p, q and q triplets
pq = list(itertools.product(p, q))
best_pq = pq
best_mean_mae = np.inf
warnings.filterwarnings("ignore") # specify to ignore warning messages
for param in pq:
    print(param)
    try:   # some parametercombinations might lead to crash, so catch exceptions and continue
        maes = []
        for train_index, test_index in tscv.split(dataset):
            if train_index.size > 300:
                # initialize cross validation train and test sets
                cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]

                # build model
                model = VARMAX(cv_train, order=(param))
                model_fit = model.fit()

                # make predictions
                predictions =  model_fit.forecast(steps=24, dynamic=False)
                prediction_values = predictions[['ice_extent']].values
                true_values = cv_test[['ice_extent']].values
                # error calc
                maes.append(mean_absolute_error(true_values, prediction_values))

        
        mean_mae = np.mean(maes)
        print('MAE: ' + str(mean_mae))    

        if mean_mae < best_mean_mae:
            best_mean_mae = mean_mae
            best_maes = maes
            best_pq = param
            best_predictions = prediction_values
    except Exception as e:
        print(e)
        continue
   
# plot
print()
print('Best MAE = ' + str(best_mean_mae))
print(best_pq)

# best range(0,5)
# Best MAE = 0.1772618201196872
# (1, 1)
# Wall time: 7min 53s


# In[175]:


best_pq = (4,1)


# In[176]:


from statsmodels.tsa.statespace.varmax import VARMAX
from sklearn.metrics import mean_absolute_error
import timeit


start_time = timeit.default_timer()

warnings.filterwarnings("ignore") # specify to ignore warning messages

print("-------")

maes = []

for train_index, test_index in tscv.split(dataset):
    if train_index.size > 300:
        # initialize cross validation train and test sets
        cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]

        # build model
        model = VARMAX(cv_train, order=(best_pq))
        model_fit = model.fit()

        # make predictions
        predictions =  model_fit.forecast(steps=24, dynamic=False)
        prediction_values = predictions[['ice_extent']].values
        true_values = cv_test[['ice_extent']].values
        # error calc
        maes.append(mean_absolute_error(true_values, prediction_values))

        print("I",end="")
    

time_VARMAX = timeit.default_timer() - start_time
mae_mean = np.mean(maes)
MAE_VARMAX = mae_mean
last_MAE_VARMAX = maes[-1]
last_predictions_VARMAX = prediction_values

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_VARMAX)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_VARMAX)
print('Execution time: %.3f seconds' % time_VARMAX)
full_graph(prediction_values, 'Last prediction VARMAX')
print(maes)


# ## Seasonal differencing

# In[13]:


from statsmodels.tsa.statespace.varmax import VARMAX
import itertools
import warnings
import sys
from sklearn.metrics import mean_absolute_error



# Define the p, d and q parameters to take any value between 0 and 2
p = q = range(0, 5)

# Generate all different combinations of p, q and q triplets
pq = list(itertools.product(p, q))
best_pq = pq
best_mean_mae = np.inf
warnings.filterwarnings("ignore") # specify to ignore warning messages
for param in pq:
    print(param)
    try:   # some parametercombinations might lead to crash, so catch exceptions and continue
        maes = []
        for train_index, test_index in tscv.split(ts_diff_seasonal):
            if train_index.size > 300:
                # initialize cross validation train and test sets
                cv_train, cv_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

                # build model
                model = VARMAX(cv_train, order=(param))
                model_fit = model.fit()

                # make predictions
                predictions =  model_fit.forecast(steps=24, dynamic=False)
                prediction_values = predictions[['ice_extent']].values
                true_values = cv_test[['ice_extent']].values
                # error calc
                maes.append(mean_absolute_error(true_values, prediction_values))

        
        mean_mae = np.mean(maes)
        print('MAE: ' + str(mean_mae))    

        if mean_mae < best_mean_mae:
            best_mean_mae = mean_mae
            best_maes = maes
            best_pq = param
            best_predictions = prediction_values
    except Exception as e:
        print(e)
        continue
   
# plot
print()
print('Best MAE = ' + str(best_mean_mae))
print(best_pq)

# best range(0,5) = (0,1)


# In[70]:


best_pq = (0,1)


# In[163]:


from statsmodels.tsa.statespace.varmax import VARMAX
from sklearn.metrics import mean_absolute_error
import timeit


start_time = timeit.default_timer()

warnings.filterwarnings("ignore") # specify to ignore warning messages

print("-------")

maes = []

for train_index, test_index in tscv.split(ts_diff_seasonal):
    if train_index.size > 300:
        # initialize cross validation train and test sets
        cv_train, cv_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

        # build model
        model = VARMAX(cv_train, order=(best_pq))
        model_fit = model.fit()

        # make predictions
        predictions =  model_fit.forecast(steps=24, dynamic=False)
        prediction_values = predictions[['ice_extent']].values
        true_values = cv_test[['ice_extent']].values
        # error calc
        maes.append(mean_absolute_error(true_values, prediction_values))

        print("I",end="")
    

time_VARMAX_seasonal = timeit.default_timer() - start_time
mae_mean_seasonal = np.mean(maes)
MAE_VARMAX_seasonal = mae_mean
last_MAE_VARMAX_seasonal = maes[-1]
last_predictions_VARMAX_seasonal = prediction_values

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_VARMAX_seasonal)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_VARMAX_seasonal)
print('Execution time: %.3f seconds' % time_VARMAX_seasonal)
full_graph_seasonal(last_predictions_VARMAX_seasonal, 'Last prediction VARMAX')
print(maes)


# # SARIMAX

# In[171]:


# setting up values for displaying prediction of the last 2 years
data = dataset
test_size = 24
data_train = data[:-test_size]
data_test = data[-test_size:]


# In[194]:


# singular test

import itertools
import warnings
import sys
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.arima_model import ARIMA

from sklearn.metrics import mean_absolute_error

warnings.filterwarnings("ignore") # specify to ignore warning messages

# Variables
endog = data_train[['ice_extent']]
exog = sm.add_constant(data_train[['mean_temp']])
exog_test = sm.add_constant(data_test[['mean_temp']])

# Fit the model
mod = sm.tsa.statespace.SARIMAX(endog, exog)

# fit model
model_fit = model.fit()

yhat = model_fit.forecast(steps = 24, exog=exog_test)

mae = mean_absolute_error(yhat, data_test[['ice_extent']])

# plot
print(mae)
plt.plot(data_test[['ice_extent']], color='blue')
plt.plot(yhat, color='red')
plt.show()


# Adding exogenous variables with SARIMAX requires to give the mean temperatures from the testset for forecasting, which is not in line with the other usecases, therefore it won't be further explored
# (extra research!)

# # LSTM

# ## Random walk diff

# In[72]:


ts


# In[73]:


# multivariate multi-step encoder-decoder lstm example
from numpy import array
from numpy import hstack
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
from keras.layers import RepeatVector
from keras.layers import TimeDistributed
import warnings

warnings.filterwarnings("ignore") # specify to ignore warning messages


# split a multivariate sequence into samples
def split_sequences(sequences, n_steps_in, n_steps_out):
	X, y = list(), list()
	for i in range(len(sequences)):
		# find the end of this pattern
		end_ix = i + n_steps_in
		out_end_ix = end_ix + n_steps_out
		# check if we are beyond the dataset
		if out_end_ix > len(sequences):
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]
		X.append(seq_x)
		y.append(seq_y)
	return array(X), array(y)

def predict_LSTM(train, test, n_neurons, n_epochs):
    test['sum'] = test['mean_temp'] + test['ice_extent']


    # define input sequence
    in_seq1 = train.values[:,0]
    in_seq2 = train.values[:,1]
    out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])

    # convert to [rows, columns] structure
    in_seq1 = in_seq1.reshape((len(in_seq1), 1))
    in_seq2 = in_seq2.reshape((len(in_seq2), 1))
    out_seq = out_seq.reshape((len(out_seq), 1))
    
    # horizontally stack columns
    dataset = hstack((in_seq1, in_seq2, out_seq))
    
    # choose a number of time steps
    n_steps_in, n_steps_out = 24, 24
    
    # covert into input/output
    X, y = split_sequences(dataset, n_steps_in, n_steps_out)
    
    # the dataset knows the number of features, e.g. 2
    n_features = X.shape[2]
    
    # define model
    model = Sequential()
    model.add(LSTM(n_neurons, activation='relu', input_shape=(n_steps_in, n_features)))
    model.add(RepeatVector(n_steps_out))
    model.add(LSTM(n_neurons, activation='relu', return_sequences=True))
    model.add(TimeDistributed(Dense(n_features)))
    model.compile(optimizer='adam', loss='mae')
    
    # fit model
    model.fit(X, y, epochs=n_epochs, verbose=0)
    
    # demonstrate prediction
    x_input = test.values
    x_input = x_input.reshape((1, n_steps_in, n_features))
    yhat = model.predict(x_input, verbose=0)
    return yhat
    


# In[18]:


from statsmodels.tsa.statespace.varmax import VARMAX
from sklearn.metrics import mean_absolute_error
import timeit
import tensorflow as tf

start_time = timeit.default_timer()

# warnings.filterwarnings("ignore") # specify to ignore warning messages
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

maes = []
global_maes = []
best_MAE = np.inf


# n_neurons_array = [1,5,10,20]
# n_epochs_array = [100,200,300]

n_neurons_array = [1, 5, 10, 20, 30]
n_epochs_array = [100,200,300]


print("-------")

maes = []
for n_neurons in n_neurons_array:
    for n_epochs in n_epochs_array:
        for train_index, test_index in tscv.split(dataset):
            if train_index.size > 300:
                # initialize cross validation train and test sets
                cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]

                yhat = predict_LSTM(cv_train, cv_test, n_neurons, n_epochs)


                prediction_values = yhat[0][:,0]
                true_values = cv_test[['ice_extent']].values

                # error calc
                maes.append(mean_absolute_error(true_values, prediction_values))

                print("I",end="")
        time_LSTM = timeit.default_timer() - start_time
        MAE_LSTM = np.mean(maes)
        last_MAE_LSTM = maes[-1]
        global_maes.append(MAE_LSTM)

        if best_MAE > MAE_LSTM:
            best_n_neurons = n_neurons
            best_n_epochs = n_epochs
            best_MAE = MAE_LSTM

        print()
        print(n_neurons)
        print(n_epochs)
        print(MAE_LSTM)
        print()    

print('Best:')
print('N neurons')
print(best_n_neurons)
print('Epochs size')
print(best_n_epochs)
print('MAE')
print(best_MAE)
plt.bar(range(0,len(global_maes)), global_maes)


# In[177]:


best_n_neurons, best_n_epochs = 30, 300


# In[178]:


from sklearn.metrics import mean_absolute_error
import timeit
import tensorflow as tf

start_time = timeit.default_timer()

# warnings.filterwarnings("ignore") # specify to ignore warning messages
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


print("-------")

maes = []

for train_index, test_index in tscv.split(dataset):
    if train_index.size > 300:
        # initialize cross validation train and test sets
        cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]
        yhat = predict_LSTM(cv_train, cv_test, best_n_neurons, best_n_epochs)


        prediction_values = yhat[0][:,0]
        true_values = cv_test[['ice_extent']].values

        # error calc
        maes.append(mean_absolute_error(true_values, prediction_values))

        print("I",end="")
    

time_LSTM = timeit.default_timer() - start_time
mae_mean = np.mean(maes)
MAE_LSTM = mae_mean
last_MAE_LSTM = maes[-1]
last_predictions_LSTM = prediction_values

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_LSTM)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_LSTM)
print('Execution time: %.3f seconds' % time_LSTM)
full_graph(last_predictions_LSTM, 'Last prediction LSTM')
print(maes)


# ## Seasonal differencing

# In[76]:


from statsmodels.tsa.statespace.varmax import VARMAX
from sklearn.metrics import mean_absolute_error
import timeit
import tensorflow as tf

start_time = timeit.default_timer()

# warnings.filterwarnings("ignore") # specify to ignore warning messages
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

maes = []
global_maes = []
best_MAE = np.inf


# n_neurons_array = [1,5,10,20]
# n_epochs_array = [100,200,300]

n_neurons_array = [1, 5, 10, 20, 30]
n_epochs_array = [100,200,300]


print("-------")

maes = []
for n_neurons in n_neurons_array:
    for n_epochs in n_epochs_array:
        for train_index, test_index in tscv.split(ts_diff_seasonal):
            if train_index.size > 300:
                # initialize cross validation train and test sets
                cv_train, cv_test = ts_diff_seasonal.iloc[train_index], ts_diff_seasonal.iloc[test_index]

                yhat = predict_LSTM(cv_train, cv_test, n_neurons, n_epochs)


                prediction_values = yhat[0][:,0]
                true_values = cv_test[['ice_extent']].values

                # error calc
                maes.append(mean_absolute_error(true_values, prediction_values))

                print("I",end="")
        time_LSTM = timeit.default_timer() - start_time
        MAE_LSTM = np.mean(maes)
        last_MAE_LSTM = maes[-1]
        global_maes.append(MAE_LSTM)

        if best_MAE > MAE_LSTM:
            best_n_neurons = n_neurons
            best_n_epochs = n_epochs
            best_MAE = MAE_LSTM

        print()
        print(n_neurons)
        print(n_epochs)
        print(MAE_LSTM)
        print()    

print('Best:')
print('N neurons')
print(best_n_neurons)
print('Epochs size')
print(best_n_epochs)
print('MAE')
print(best_MAE)
plt.bar(range(0,len(global_maes)), global_maes)


# In[164]:


best_n_neurons, best_n_epochs = 1, 200


# In[165]:


from sklearn.metrics import mean_absolute_error
import timeit
import tensorflow as tf

start_time = timeit.default_timer()

# warnings.filterwarnings("ignore") # specify to ignore warning messages
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


print("-------")

maes = []

for train_index, test_index in tscv.split(dataset):
    if train_index.size > 300:
        # initialize cross validation train and test sets
        cv_train, cv_test = dataset.iloc[train_index], dataset.iloc[test_index]
        yhat = predict_LSTM(cv_train, cv_test, best_n_neurons, best_n_epochs)


        prediction_values = yhat[0][:,0]
        true_values = cv_test[['ice_extent']].values

        # error calc
        maes.append(mean_absolute_error(true_values, prediction_values))

        print("I",end="")
    

time_LSTM_seasonal = timeit.default_timer() - start_time
mae_mean_seasonal = np.mean(maes)
MAE_LSTM_seasonal = mae_mean
last_MAE_LSTM_seasonal = maes[-1]
last_predictions_LSTM_seasonal = prediction_values

print()
print('Mean MAE: %.3f x 1 000 000 km\u00b2' % MAE_LSTM_seasonal)
print('MAE of last prediction: %.3f x 1 000 000 km\u00b2' % last_MAE_LSTM_seasonal)
print('Execution time: %.3f seconds' % time_LSTM_seasonal)
full_graph_seasonal(last_predictions_LSTM_seasonal, 'Last prediction LSTM')
print(maes)


# # Evaluation

# In[181]:


# formatting
results = [[MAE_VARMAX, time_VARMAX, last_MAE_VARMAX],
           [MAE_VARMAX_seasonal, time_VARMAX_seasonal, last_MAE_VARMAX_seasonal],
           [MAE_LSTM, time_LSTM, last_MAE_LSTM],
           [MAE_LSTM_seasonal, time_LSTM_seasonal, last_MAE_LSTM_seasonal]]

# display results
results = pd.DataFrame(results, columns=['Mean MAE (x 1 000 000 km\u00b2)','Execution time (s)','Last MAE (x 1 000 000 km\u00b2)']
             ,index=['VARMAX','VARMAX_seasonal','LSTM','LSTM_seasonal']).round(decimals=3)
results


# In[182]:


full_graph(last_predictions_VARMAX, 'Last prediction VARMAX with random walk differencing')
full_graph_seasonal(last_predictions_VARMAX_seasonal, 'Last prediction VARMAX with seasonal differencing')
full_graph(last_predictions_LSTM, 'Last prediction LSTM with random walk differencing')
full_graph_seasonal(last_predictions_LSTM_seasonal, 'Last prediction LSTM with seasonal differencing')
\end{minted}

